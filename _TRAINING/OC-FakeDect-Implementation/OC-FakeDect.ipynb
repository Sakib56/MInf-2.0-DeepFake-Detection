{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "bbec6071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "6c821ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$RECYCLE.BIN', '.Trash-1000', 'Config.Msi', 'GOG Games', 'MInf', 'OneDriveTemp', 'Program Files', 'Program Files (x86)', 'Riot Games', 'System Volume Information', 'TDDS-G35-CW3', 'Users', 'WindowsApps', 'WpSystem', 'WUDownloadCache']\n",
      "\n",
      "['Comparing-the-Performance-of-Deepfake-Detection-Methods-on-Benchmark-Datasets-master', 'DariusAf_MesoNet', 'Datasets', 'Kiteco_Deepfake_Detection', 'MInf-DeepfakeDetection-FrameDifferencing', 'MLP-DeepfakeDetection-VariationalAutoencoder', '_BASELINE_TESTS', '_TRAINING']\n",
      "\n",
      "['Celeb-DF-v2', 'Celeb-DF-v2-OC', 'DariusAf_Deepfake_Database', 'DariusAf_Deepfake_Database-OC', 'FaceForensicspp']\n",
      "\n",
      "['real-train', 'realfake-test']\n",
      "\n",
      "['real']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data_path = \"D:\\MInf\\Datasets\\Celeb-DF-v2-OC\\Celeb-rnd-30-OC-real-train\".replace(\"\\\\\", \"/\")\n",
    "data_path = \"D:/MInf/Datasets/DariusAf_Deepfake_Database-OC/real-train/\"\n",
    "current_subpath = \"\"\n",
    "for subpath in data_path.split(\"/\")[:-1]:\n",
    "    current_subpath += f\"{subpath}/\"\n",
    "    print(f\"{os.listdir(current_subpath)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "48057793",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 20\n",
    "train_root = data_path\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "2448359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((100,100)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((100,100)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "78ea6db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class vae(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(vae, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3,stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3,stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3,stride=1, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 32, kernel_size=3,stride=2, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.fc1 = nn.Linear(25 * 25 * 32, 1000)\n",
    "        self.fc1_bn = nn.BatchNorm1d(1000)\n",
    "        self.fc2_mean = nn.Linear(1000, 100)\n",
    "        self.fc2_logvar = nn.Linear(1000, 100)\n",
    "\n",
    "        self.fc3 = nn.Linear(100, 1000)\n",
    "        self.fc3_bn = nn.BatchNorm1d(1000)\n",
    "        self.fc4 = nn.Linear(1000, 25 * 25 * 32)\n",
    "        self.fc4_bn = nn.BatchNorm1d(25 * 25 * 32)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.conv5 = nn.ConvTranspose2d(32, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn5 = nn.BatchNorm2d(64)\n",
    "        self.conv6 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False)\n",
    "        self.bn6 = nn.BatchNorm2d(32)\n",
    "        self.conv7 = nn.ConvTranspose2d(32, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn7 = nn.BatchNorm2d(16)\n",
    "        self.conv8 = nn.ConvTranspose2d(16, 3, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False)\n",
    "        \n",
    "    def encode(self, data):\n",
    "        conv1 = self.relu(self.bn1(self.conv1(data)))\n",
    "        conv2 = self.relu(self.bn2(self.conv2(conv1)))\n",
    "        conv3 = self.relu(self.bn3(self.conv3(conv2)))\n",
    "        conv4 = self.relu(self.bn4(self.conv4(conv3)))\n",
    "\n",
    "        fc1 = self.relu(self.fc1_bn(self.fc1(conv4.view(-1, 25 * 25 * 32))))\n",
    "        mean = self.fc2_mean(fc1)\n",
    "        logvar = self.fc2_logvar(fc1)\n",
    "        return mean, logvar\n",
    "    \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = 0.5 * torch.exp(logvar)\n",
    "        z = (std.data.new(std.size()).normal_()) * std + mean\n",
    "        return z\n",
    "    \n",
    "    def decode(self, z):\n",
    "        fc3 = self.relu(self.fc3_bn(self.fc3(z)))\n",
    "        fc4 = self.relu(self.fc4_bn(self.fc4(fc3)))\n",
    "        conv5 = self.relu(self.bn5(self.conv5(fc4.view(-1, 32, 25, 25))))\n",
    "        conv6 = self.relu(self.bn6(self.conv6(conv5)))\n",
    "        conv7 = self.relu(self.bn7(self.conv7(conv6)))\n",
    "        conv8 = self.conv8(conv7)\n",
    "        return conv8.view(-1, 3, 100, 100)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        return self.decode(z), mean, logvar\n",
    "\n",
    "def loss_function(recon_x, x, mean, logvar):\n",
    "    mse_loss = nn.MSELoss(reduction=\"sum\")\n",
    "    reconstruction_loss = mse_loss(recon_x, x)\n",
    "    kld_loss = -0.5 * torch.sum(1+logvar-torch.exp(logvar)-mean**2)\n",
    "    return reconstruction_loss + kld_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "426ae5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 16, 100, 100]        432\n",
      "├─BatchNorm2d: 1-2                       [-1, 16, 100, 100]        32\n",
      "├─ReLU: 1-3                              [-1, 16, 100, 100]        --\n",
      "├─Conv2d: 1-4                            [-1, 32, 50, 50]          4,608\n",
      "├─BatchNorm2d: 1-5                       [-1, 32, 50, 50]          64\n",
      "├─ReLU: 1-6                              [-1, 32, 50, 50]          --\n",
      "├─Conv2d: 1-7                            [-1, 64, 50, 50]          18,432\n",
      "├─BatchNorm2d: 1-8                       [-1, 64, 50, 50]          128\n",
      "├─ReLU: 1-9                              [-1, 64, 50, 50]          --\n",
      "├─Conv2d: 1-10                           [-1, 32, 25, 25]          18,432\n",
      "├─BatchNorm2d: 1-11                      [-1, 32, 25, 25]          64\n",
      "├─ReLU: 1-12                             [-1, 32, 25, 25]          --\n",
      "├─Linear: 1-13                           [-1, 1000]                20,001,000\n",
      "├─BatchNorm1d: 1-14                      [-1, 1000]                2,000\n",
      "├─ReLU: 1-15                             [-1, 1000]                --\n",
      "├─Linear: 1-16                           [-1, 100]                 100,100\n",
      "├─Linear: 1-17                           [-1, 100]                 100,100\n",
      "├─Linear: 1-18                           [-1, 1000]                101,000\n",
      "├─BatchNorm1d: 1-19                      [-1, 1000]                2,000\n",
      "├─ReLU: 1-20                             [-1, 1000]                --\n",
      "├─Linear: 1-21                           [-1, 20000]               20,020,000\n",
      "├─BatchNorm1d: 1-22                      [-1, 20000]               40,000\n",
      "├─ReLU: 1-23                             [-1, 20000]               --\n",
      "├─ConvTranspose2d: 1-24                  [-1, 64, 25, 25]          18,432\n",
      "├─BatchNorm2d: 1-25                      [-1, 64, 25, 25]          128\n",
      "├─ReLU: 1-26                             [-1, 64, 25, 25]          --\n",
      "├─ConvTranspose2d: 1-27                  [-1, 32, 50, 50]          18,432\n",
      "├─BatchNorm2d: 1-28                      [-1, 32, 50, 50]          64\n",
      "├─ReLU: 1-29                             [-1, 32, 50, 50]          --\n",
      "├─ConvTranspose2d: 1-30                  [-1, 16, 50, 50]          4,608\n",
      "├─BatchNorm2d: 1-31                      [-1, 16, 50, 50]          32\n",
      "├─ReLU: 1-32                             [-1, 16, 50, 50]          --\n",
      "├─ConvTranspose2d: 1-33                  [-1, 3, 100, 100]         432\n",
      "==========================================================================================\n",
      "Total params: 40,450,520\n",
      "Trainable params: 40,450,520\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 187.20\n",
      "==========================================================================================\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 9.42\n",
      "Params size (MB): 154.31\n",
      "Estimated Total Size (MB): 163.84\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 16, 100, 100]        432\n",
      "├─BatchNorm2d: 1-2                       [-1, 16, 100, 100]        32\n",
      "├─ReLU: 1-3                              [-1, 16, 100, 100]        --\n",
      "├─Conv2d: 1-4                            [-1, 32, 50, 50]          4,608\n",
      "├─BatchNorm2d: 1-5                       [-1, 32, 50, 50]          64\n",
      "├─ReLU: 1-6                              [-1, 32, 50, 50]          --\n",
      "├─Conv2d: 1-7                            [-1, 64, 50, 50]          18,432\n",
      "├─BatchNorm2d: 1-8                       [-1, 64, 50, 50]          128\n",
      "├─ReLU: 1-9                              [-1, 64, 50, 50]          --\n",
      "├─Conv2d: 1-10                           [-1, 32, 25, 25]          18,432\n",
      "├─BatchNorm2d: 1-11                      [-1, 32, 25, 25]          64\n",
      "├─ReLU: 1-12                             [-1, 32, 25, 25]          --\n",
      "├─Linear: 1-13                           [-1, 1000]                20,001,000\n",
      "├─BatchNorm1d: 1-14                      [-1, 1000]                2,000\n",
      "├─ReLU: 1-15                             [-1, 1000]                --\n",
      "├─Linear: 1-16                           [-1, 100]                 100,100\n",
      "├─Linear: 1-17                           [-1, 100]                 100,100\n",
      "├─Linear: 1-18                           [-1, 1000]                101,000\n",
      "├─BatchNorm1d: 1-19                      [-1, 1000]                2,000\n",
      "├─ReLU: 1-20                             [-1, 1000]                --\n",
      "├─Linear: 1-21                           [-1, 20000]               20,020,000\n",
      "├─BatchNorm1d: 1-22                      [-1, 20000]               40,000\n",
      "├─ReLU: 1-23                             [-1, 20000]               --\n",
      "├─ConvTranspose2d: 1-24                  [-1, 64, 25, 25]          18,432\n",
      "├─BatchNorm2d: 1-25                      [-1, 64, 25, 25]          128\n",
      "├─ReLU: 1-26                             [-1, 64, 25, 25]          --\n",
      "├─ConvTranspose2d: 1-27                  [-1, 32, 50, 50]          18,432\n",
      "├─BatchNorm2d: 1-28                      [-1, 32, 50, 50]          64\n",
      "├─ReLU: 1-29                             [-1, 32, 50, 50]          --\n",
      "├─ConvTranspose2d: 1-30                  [-1, 16, 50, 50]          4,608\n",
      "├─BatchNorm2d: 1-31                      [-1, 16, 50, 50]          32\n",
      "├─ReLU: 1-32                             [-1, 16, 50, 50]          --\n",
      "├─ConvTranspose2d: 1-33                  [-1, 3, 100, 100]         432\n",
      "==========================================================================================\n",
      "Total params: 40,450,520\n",
      "Trainable params: 40,450,520\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 187.20\n",
      "==========================================================================================\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 9.42\n",
      "Params size (MB): 154.31\n",
      "Estimated Total Size (MB): 163.84\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(train_root, \n",
    "                         transform=transform_train),\n",
    "                         batch_size=batch_size, \n",
    "                         shuffle=True,\n",
    "                         drop_last = True)\n",
    "fakedect = vae().to(device)\n",
    "optimizer = optim.Adam(fakedect.parameters(), lr=5e-4)\n",
    "print(summary(fakedect, (3, 100, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "9b2fd789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0\tloss=1340.2490\n",
      "epoch=0\tloss=1252.3209\n",
      "epoch=0\tloss=1111.9975\n",
      "epoch=0\tloss=1197.1976\n",
      "epoch=0\tloss=1144.8364\n",
      "epoch=0\tloss=1206.5239\n",
      "epoch=0\tloss=1294.3717\n",
      "epoch=0\tloss=1369.9961\n",
      "epoch=0\tloss=1100.8050\n",
      "epoch=0\tloss=1458.3290\n",
      "epoch=0\tloss=1266.1847\n",
      "epoch=0\tloss=1128.0562\n",
      "epoch=0\tloss=1218.1675\n",
      "epoch=0\tloss=1366.3992\n",
      "epoch=0\tloss=1149.6869\n",
      "epoch=0\tloss=1236.7326\n",
      "epoch=0\tloss=1242.5061\n",
      "epoch=0\tloss=1306.3407\n",
      "epoch=0\tloss=1240.8061\n",
      "epoch=0\tloss=1282.9186\n",
      "epoch=0\tloss=1202.6139\n",
      "epoch=0\tloss=1252.2254\n",
      "epoch=0\tloss=1247.6032\n",
      "epoch=0\tloss=1241.6261\n",
      "epoch=0\tloss=1432.3474\n",
      "epoch=0\tloss=1215.3780\n",
      "epoch=0\tloss=1221.4236\n",
      "epoch=0\tloss=1221.0569\n",
      "epoch=0\tloss=1793.8488\n",
      "epoch=0\tloss=1265.7001\n",
      "epoch=0\tloss=1369.7297\n",
      "epoch=0\tloss=1362.0978\n",
      "epoch=0\tloss=1314.0267\n",
      "epoch=0\tloss=1330.3936\n",
      "epoch=0\tloss=1363.3656\n",
      "epoch=0\tloss=1104.9962\n",
      "epoch=0\tloss=1318.1011\n",
      "epoch=0\tloss=1203.0041\n",
      "epoch=0\tloss=1314.6617\n",
      "epoch=0\tloss=1204.9357\n",
      "epoch=0\tloss=1237.0237\n",
      "epoch=0\tloss=1431.6031\n",
      "epoch=0\tloss=1470.1802\n",
      "epoch=0\tloss=1130.5671\n",
      "epoch=0\tloss=1248.4158\n",
      "epoch=0\tloss=1314.5853\n",
      "epoch=0\tloss=1151.4044\n",
      "epoch=0\tloss=1377.2004\n",
      "epoch=0\tloss=1291.9980\n",
      "epoch=0\tloss=1318.0219\n",
      "epoch=0\tloss=1116.1155\n",
      "epoch=0\tloss=1165.5245\n",
      "epoch=0\tloss=1273.2403\n",
      "epoch=0\tloss=1147.5063\n",
      "epoch=0\tloss=1152.5054\n",
      "epoch=0\tloss=1116.7142\n",
      "epoch=0\tloss=1184.0004\n",
      "epoch=0\tloss=1078.4844\n",
      "epoch=0\tloss=1074.2624\n",
      "epoch=0\tloss=1064.5794\n",
      "epoch=0\tloss=1589.5384\n",
      "epoch=0\tloss=1105.9502\n",
      "epoch=0\tloss=1179.6115\n",
      "epoch=0\tloss=1147.0185\n",
      "epoch=0\tloss=1233.4811\n",
      "epoch=0\tloss=1249.3868\n",
      "epoch=0\tloss=1180.2080\n",
      "epoch=0\tloss=1398.5103\n",
      "epoch=0\tloss=1132.5650\n",
      "epoch=0\tloss=1300.5633\n",
      "epoch=0\tloss=1154.4744\n",
      "epoch=0\tloss=1407.4970\n",
      "epoch=0\tloss=1402.0312\n",
      "epoch=0\tloss=1234.6374\n",
      "epoch=0\tloss=1491.0537\n",
      "epoch=0\tloss=1274.6462\n",
      "epoch=0\tloss=1267.6266\n",
      "epoch=0\tloss=1230.7519\n",
      "epoch=0\tloss=1173.7884\n",
      "epoch=0\tloss=1192.8128\n",
      "epoch=0\tloss=1176.0030\n",
      "epoch=0\tloss=1075.2533\n",
      "epoch=0\tloss=1325.0307\n",
      "epoch=0\tloss=1224.0408\n",
      "epoch=0\tloss=1190.0910\n",
      "epoch=0\tloss=1320.0825\n",
      "epoch=0\tloss=1086.4087\n",
      "epoch=0\tloss=1179.4090\n",
      "epoch=0\tloss=1271.3064\n",
      "epoch=0\tloss=1138.0627\n",
      "epoch=0\tloss=1073.4517\n",
      "epoch=0\tloss=1318.0822\n",
      "epoch=0\tloss=1204.3053\n",
      "epoch=0\tloss=1199.8090\n",
      "epoch=0\tloss=1150.3432\n",
      "epoch=0\tloss=1091.3597\n",
      "epoch=0\tloss=1315.1697\n",
      "epoch=0\tloss=1281.7304\n",
      "epoch=0\tloss=1370.6276\n",
      "epoch=0\tloss=1514.6706\n",
      "epoch=0\tloss=1185.7044\n",
      "epoch=0\tloss=1324.5517\n",
      "epoch=0\tloss=1058.9551\n",
      "epoch=0\tloss=1236.7866\n",
      "epoch=0\tloss=1219.6655\n",
      "epoch=0\tloss=1256.5083\n",
      "epoch=0\tloss=1293.6781\n",
      "epoch=0\tloss=1232.9402\n",
      "epoch=0\tloss=1156.9780\n",
      "epoch=0\tloss=1179.2022\n",
      "epoch=0\tloss=1203.1078\n",
      "epoch=0\tloss=1260.3961\n",
      "epoch=0\tloss=1237.0456\n",
      "epoch=1\tloss=1248.4109\n",
      "epoch=1\tloss=1236.9912\n",
      "epoch=1\tloss=1104.4400\n",
      "epoch=1\tloss=1115.6007\n",
      "epoch=1\tloss=1220.8217\n",
      "epoch=1\tloss=1401.4331\n",
      "epoch=1\tloss=1299.2347\n",
      "epoch=1\tloss=1142.8717\n",
      "epoch=1\tloss=1210.6968\n",
      "epoch=1\tloss=1209.2997\n",
      "epoch=1\tloss=1376.6775\n",
      "epoch=1\tloss=1244.4307\n",
      "epoch=1\tloss=1222.3665\n",
      "epoch=1\tloss=1311.1564\n",
      "epoch=1\tloss=1397.4863\n",
      "epoch=1\tloss=1276.6457\n",
      "epoch=1\tloss=1199.4897\n",
      "epoch=1\tloss=1168.5622\n",
      "epoch=1\tloss=1156.9451\n",
      "epoch=1\tloss=1246.2488\n",
      "epoch=1\tloss=1156.1060\n",
      "epoch=1\tloss=1313.2538\n",
      "epoch=1\tloss=1308.2387\n",
      "epoch=1\tloss=1280.6413\n",
      "epoch=1\tloss=1222.3933\n",
      "epoch=1\tloss=1315.8243\n",
      "epoch=1\tloss=1191.0185\n",
      "epoch=1\tloss=1330.7175\n",
      "epoch=1\tloss=1145.7597\n",
      "epoch=1\tloss=1251.1376\n",
      "epoch=1\tloss=1203.6146\n",
      "epoch=1\tloss=1203.9903\n",
      "epoch=1\tloss=1316.0761\n",
      "epoch=1\tloss=1810.3497\n",
      "epoch=1\tloss=1088.2776\n",
      "epoch=1\tloss=1302.2994\n",
      "epoch=1\tloss=1430.6166\n",
      "epoch=1\tloss=1249.0905\n",
      "epoch=1\tloss=1121.4614\n",
      "epoch=1\tloss=1176.0138\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [308]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 18\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m L \u001b[38;5;241m=\u001b[39m train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mloss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mL\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "weights_path = \"D:/MInf/_TRAINING/OC-FakeDect-Implementation/OC_FD_e22_l1401.pkl\"\n",
    "fakedect = torch.load(weights_path)\n",
    "\n",
    "min_loss = float(\"inf\")\n",
    "for epoch in range(3):\n",
    "    fakedect.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (inputs, _) in enumerate(train_loader):\n",
    "        train_loss = 0\n",
    "        for i in range(100):\n",
    "            inputs = inputs.to(device)\n",
    "            gen_imgs, mean, logvar = fakedect(inputs)\n",
    "            loss = loss_function(gen_imgs, inputs, mean, logvar)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        L = train_loss / len(train_loader.dataset)\n",
    "        print(f\"{epoch=}\\tloss={L:.4f}\")\n",
    "    # if L < min_loss:\n",
    "    #     min_loss = L\n",
    "    #     torch.save(fakedect, f\"OC_FD_e{epoch+1}_l{int(L)}.pkl\")\n",
    "    # print('Epoch: {}  loss: {:.4f}'.format(\n",
    "    #     epoch, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a90d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # single_batch = \n",
    "# for batch_idx, (inputs, _) in enumerate(train_loader):\n",
    "#     single_batch = inputs.to(device)\n",
    "#     break\n",
    "\n",
    "# for epoch in tqdm(range(3000), total=epochs, delay=60):\n",
    "#     fakedect.train()\n",
    "#     train_loss = 0\n",
    "#     # for batch_idx, (inputs, _) in enumerate(train_loader):\n",
    "#     single_batch = inputs\n",
    "#     inputs = inputs.to(device)\n",
    "#     gen_imgs, mean, logvar = fakedect(inputs)\n",
    "#     loss = loss_function(gen_imgs, inputs, mean, logvar)\n",
    "\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     train_loss += loss.item()\n",
    "#     L = train_loss / len(train_loader.dataset)\n",
    "#     print(f\"{epoch=}\\tloss={L:.4f}\")\n",
    "#     # print('Epoch: {}  loss: {:.4f}'.format(\n",
    "#     #     epoch, ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04790a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9812c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# for i in range(5,5+10):\n",
    "#     test_im = single_batch[i]\n",
    "#     img = test_im.view(3,100,100).cpu()\n",
    "#     img = 255*(img*0.5 + 0.5).numpy()\n",
    "#     img = img.astype(int)\n",
    "#     # img = (img).numpy()\n",
    "#     img = np.moveaxis(img, 0, -1)\n",
    "#     # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#     # print(type(img))\n",
    "#     # print(img.shape)\n",
    "#     # print(img)\n",
    "#     # # img = 255*(img*0.5 + 0.5).numpy()\n",
    "#     # img = np.moveaxis(img, 0, -1)\n",
    "#     # # img.shape\n",
    "#     # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     # plt.imshow(img)\n",
    "#     pp = img\n",
    "#     # plt.show()\n",
    "\n",
    "#     # # img = \n",
    "\n",
    "#     # plt.imshow(img)\n",
    "#     # img = image.float().to(\"cpu\")\n",
    "#     with torch.no_grad():\n",
    "#         image = test_im\n",
    "#         # print(image.shape)\n",
    "#         x = image.view(-1,3,100,100)\n",
    "#         print(x.shape)\n",
    "#         decode_z, mean_z, logvar_z = fakedect(x)\n",
    "#         # print(decode_z.shape )\n",
    "#     decode_z = decode_z.view(3,100,100).cpu()\n",
    "#     decode_z = 255*(decode_z*0.5 + 0.5).numpy()\n",
    "#     decode_z = decode_z.astype(int)\n",
    "#     plt.subplot(1,2,1)\n",
    "#     # print(np.array(img[::-1].shape))\n",
    "#     # print(decode_z.transpose(1,2,0).shape)\n",
    "#     # print(img.shape)\n",
    "#     plt.imshow(pp)\n",
    "#     plt.subplot(1,2,2)\n",
    "#     plt.imshow(decode_z.transpose(1,2,0))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c260b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(fakedect, f\"OC_FD_e{epoch+1}_l{int(L)}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e10b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shwcse_img_path = \"D:/MInf/Datasets/Celeb-DF-v2-OC/Celeb-rnd-30-OC-realfake-test/Celeb-real/id11_0009_1.png\"\n",
    "# img = cv2.cvtColor(cv2.imread(shwcse_img_path), cv2.COLOR_BGR2RGB)\n",
    "# image = transform_test(img)\n",
    "# image = image.float().to(device)\n",
    "# # print(image.shape)\n",
    "# # fakedect = torch.load(weights_path)\n",
    "# fakedect.eval()\n",
    "# with torch.no_grad():\n",
    "#     x = image.view(-1,3,100,100)\n",
    "#     print(x.shape)\n",
    "#     decode_z, mean_z, logvar_z = fakedect(x)\n",
    "#     # print(decode_z.shape )\n",
    "# decode_z = decode_z.view(3,100,100).cpu()\n",
    "# decode_z = 255*(decode_z*0.5 + 0.5).numpy()\n",
    "# decode_z = decode_z.astype(int)\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.imshow(img)\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.imshow(decode_z.transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7750e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"D:\\MInf\\Datasets\\Celeb-DF-v2-OC\\Celeb-rnd-30-OC-realfake-test/\".replace(\"\\\\\", \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad06c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = {0:[],1:[]}\n",
    "# for j in os.listdir(test_path):\n",
    "#     test_img_path = test_path+j+\"/\"\n",
    "#     print(test_img_path)\n",
    "#     image = cv2.cvtColor(cv2.imread(test_img_path), cv2.COLOR_BGR2RGB)\n",
    "#     image = transform_test(image)\n",
    "#     image = image.float().to(device)\n",
    "#     fakedect.eval()\n",
    "#     with torch.no_grad():\n",
    "#         reimg = fakedect(image.view(-1,3,100,100))\n",
    "#         y = fakedect.encode(reimg[0])\n",
    "#     rsme = ((((reimg[1].cpu() - y[0].cpu())**2).sum()/1024)**0.5).item()\n",
    "#     if j[len(j) - 5] == 'l':\n",
    "#         score[1].append(rsme)\n",
    "#     else:\n",
    "#         score[0].append(rsme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7949/7949 [00:40<00:00, 193.95it/s]\n",
      "100%|██████████| 4260/4260 [00:20<00:00, 204.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# test_path = \"D:/MInf/Datasets/Celeb-DF-v2-OC/Celeb-rnd-30-OC-realfake-test\"\n",
    "test_path =  \"D:/MInf/Datasets/DariusAf_Deepfake_Database-OC/realfake-test\"\n",
    "score = {0:[],1:[]}\n",
    "for class_dir in os.listdir(f\"{test_path}/\"):\n",
    "    for test_img in tqdm(os.listdir(f\"{test_path}/{class_dir}\")):\n",
    "        # get img\n",
    "        test_img_path = f\"{test_path}/{class_dir}/{test_img}\"\n",
    "        # print(test_img_path)\n",
    "        if \".png\" in test_img_path or \".jpg\" in test_img_path or \".jpeg\" in test_img_path:\n",
    "            image = cv2.cvtColor(cv2.imread(test_img_path), cv2.COLOR_BGR2RGB)\n",
    "            image = transform_test(image)\n",
    "            image = image.float().to(device)\n",
    "\n",
    "            fakedect.eval()\n",
    "            with torch.no_grad():\n",
    "                x = image.view(-1,3,100,100)\n",
    "                x_prime, _, _ = fakedect(x)\n",
    "                z_mean, z_logvar = fakedect.encode(x_prime)\n",
    "            rsme = ((((mean_z.cpu() - z_mean.cpu())**2).sum()/1024)**0.5).item()\n",
    "            # print(class_dir)\n",
    "            if \"real\" in class_dir:\n",
    "\n",
    "                score[1].append(rsme)\n",
    "            else:\n",
    "                score[0].append(rsme)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5f8e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22703163807913854, 0.0006804116565294591)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(score[1]), np.var(score[1])\n",
    "np.mean(score[1]), np.var(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d2d275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(m1,m2,std1,std2):\n",
    "  a = 1/(2*std1**2) - 1/(2*std2**2)\n",
    "  b = m2/(std2**2) - m1/(std1**2)\n",
    "  c = m1**2 /(2*std1**2) - m2**2 / (2*std2**2) - np.log(std2/std1)\n",
    "  return np.roots([a,b,c])\n",
    "\n",
    "intersec = solve(np.mean(score[1]), np.mean(score[0]), np.var(score[1]), np.mean(score[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdbafbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x1f1ff20e820>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = [x*0.005 for x in range(0, 90)]\n",
    "plt.hist(score[0],bins,alpha=0.7)[2]\n",
    "plt.hist(score[1],bins,alpha=0.7)[2]\n",
    "plt.vlines(x=intersec[0], ymin=0, ymax=800, colors=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076d1915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When threshold is 0.22936471040855383 \n",
      "Accuracy of real pics is 56.11645926273773%\n",
      "Accuracy of fake pics is 61.9904%\n",
      "Total Accuracy is 59.9410%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "real_score = np.array(score[1])\n",
    "fake_score = np.array(score[0])\n",
    "threshold = intersec[0]\n",
    "print('When threshold is {} \\nAccuracy of real pics is {}%\\n\\\n",
    "Accuracy of fake pics is {:.4f}%\\nTotal Accuracy is {:.4f}%\\n'.format(\n",
    "    threshold,\\\n",
    "    100 * ((real_score < threshold).sum() / real_score.shape[0]),\\\n",
    "    100 * ((fake_score > threshold).sum() / fake_score.shape[0]),\\\n",
    "    100 * (((real_score < threshold).sum() + (fake_score > threshold).sum())/(real_score.shape[0] + fake_score.shape[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ef92e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
