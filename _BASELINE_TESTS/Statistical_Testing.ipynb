{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc_from_file(fpath):\n",
    "    with open(fpath, \"r\") as f:\n",
    "        f.readline()\n",
    "        auc = f.readline()\n",
    "    return float(auc.strip().split(\"=\")[-1])\n",
    "\n",
    "def get_ytrueNpreds_from_file(fpath):\n",
    "    with open(fpath, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        y_true, y_pred = lines[10], lines[12]\n",
    "\n",
    "    return ast.literal_eval(y_true.split(\"=\")[-1]), ast.literal_eval(y_pred.split(\"=\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "# AUC comparison adapted from\n",
    "# https://github.com/Netflix/vmaf/\n",
    "def compute_midrank(x):\n",
    "    \"\"\"Computes midranks.\n",
    "    Args:\n",
    "       x - a 1D numpy array\n",
    "    Returns:\n",
    "       array of midranks\n",
    "    \"\"\"\n",
    "    J = np.argsort(x)\n",
    "    Z = x[J]\n",
    "    N = len(x)\n",
    "    T = np.zeros(N, dtype=float)\n",
    "    i = 0\n",
    "    while i < N:\n",
    "        j = i\n",
    "        while j < N and Z[j] == Z[i]:\n",
    "            j += 1\n",
    "        T[i:j] = 0.5*(i + j - 1)\n",
    "        i = j\n",
    "    T2 = np.empty(N, dtype=float)\n",
    "    # Note(kazeevn) +1 is due to Python using 0-based indexing\n",
    "    # instead of 1-based in the AUC formula in the paper\n",
    "    T2[J] = T + 1\n",
    "    return T2\n",
    "\n",
    "\n",
    "def fastDeLong(predictions_sorted_transposed, label_1_count):\n",
    "    \"\"\"\n",
    "    The fast version of DeLong's method for computing the covariance of\n",
    "    unadjusted AUC.\n",
    "    Args:\n",
    "       predictions_sorted_transposed: a 2D numpy.array[n_classifiers, n_examples]\n",
    "          sorted such as the examples with label \"1\" are first\n",
    "    Returns:\n",
    "       (AUC value, DeLong covariance)\n",
    "    Reference:\n",
    "     @article{sun2014fast,\n",
    "       title={Fast Implementation of DeLong's Algorithm for\n",
    "              Comparing the Areas Under Correlated Receiver Operating Characteristic Curves},\n",
    "       author={Xu Sun and Weichao Xu},\n",
    "       journal={IEEE Signal Processing Letters},\n",
    "       volume={21},\n",
    "       number={11},\n",
    "       pages={1389--1393},\n",
    "       year={2014},\n",
    "       publisher={IEEE}\n",
    "     }\n",
    "    \"\"\"\n",
    "    # Short variables are named as they are in the paper\n",
    "    m = label_1_count\n",
    "    n = predictions_sorted_transposed.shape[1] - m\n",
    "    positive_examples = predictions_sorted_transposed[:, :m]\n",
    "    negative_examples = predictions_sorted_transposed[:, m:]\n",
    "    k = predictions_sorted_transposed.shape[0]\n",
    "\n",
    "    tx = np.empty([k, m], dtype=float)\n",
    "    ty = np.empty([k, n], dtype=float)\n",
    "    tz = np.empty([k, m + n], dtype=float)\n",
    "    for r in range(k):\n",
    "        tx[r, :] = compute_midrank(positive_examples[r, :])\n",
    "        ty[r, :] = compute_midrank(negative_examples[r, :])\n",
    "        tz[r, :] = compute_midrank(predictions_sorted_transposed[r, :])\n",
    "    aucs = tz[:, :m].sum(axis=1) / m / n - float(m + 1.0) / 2.0 / n\n",
    "    v01 = (tz[:, :m] - tx[:, :]) / n\n",
    "    v10 = 1.0 - (tz[:, m:] - ty[:, :]) / m\n",
    "    sx = np.cov(v01)\n",
    "    sy = np.cov(v10)\n",
    "    delongcov = sx / m + sy / n\n",
    "    return aucs, delongcov\n",
    "\n",
    "\n",
    "def calc_pvalue(aucs, sigma):\n",
    "    \"\"\"Computes log(10) of p-values.\n",
    "    Args:\n",
    "       aucs: 1D array of AUCs\n",
    "       sigma: AUC DeLong covariances\n",
    "    Returns:\n",
    "       log10(pvalue)\n",
    "    \"\"\"\n",
    "    l = np.array([[1, -1]])\n",
    "    z = np.abs(np.diff(aucs)) / np.sqrt(np.dot(np.dot(l, sigma), l.T))\n",
    "    return z, np.log10(2) + scipy.stats.norm.logsf(z, loc=0, scale=1) / np.log(10)\n",
    "\n",
    "\n",
    "def compute_ground_truth_statistics(ground_truth):\n",
    "    assert np.array_equal(np.unique(ground_truth), [0, 1])\n",
    "    order = (-ground_truth).argsort()\n",
    "    label_1_count = int(ground_truth.sum())\n",
    "    return order, label_1_count\n",
    "\n",
    "\n",
    "def delong_roc_variance(ground_truth, predictions):\n",
    "    \"\"\"\n",
    "    Computes ROC AUC variance for a single set of predictions\n",
    "    Args:\n",
    "       ground_truth: np.array of 0 and 1\n",
    "       predictions: np.array of floats of the probability of being class 1\n",
    "    \"\"\"\n",
    "    order, label_1_count = compute_ground_truth_statistics(ground_truth)\n",
    "    predictions_sorted_transposed = predictions[np.newaxis, order]\n",
    "    aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count)\n",
    "    assert len(aucs) == 1, \"There is a bug in the code, please forward this to the developers\"\n",
    "    print(auc[0])\n",
    "    return aucs[0], delongcov\n",
    "\n",
    "\n",
    "def delong_roc_test(ground_truth, predictions_one, predictions_two):\n",
    "    \"\"\"\n",
    "    Computes log(p-value) for hypothesis that two ROC AUCs are different\n",
    "    Args:\n",
    "       ground_truth: np.array of 0 and 1\n",
    "       predictions_one: predictions of the first model,\n",
    "          np.array of floats of the probability of being class 1\n",
    "       predictions_two: predictions of the second model,\n",
    "          np.array of floats of the probability of being class 1\n",
    "    \"\"\"\n",
    "    order, label_1_count = compute_ground_truth_statistics(ground_truth)\n",
    "    predictions_sorted_transposed = np.vstack((predictions_one, predictions_two))[:, order]\n",
    "    aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count)\n",
    "    return calc_pvalue(aucs, delongcov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath2results = \"./Results/\"\n",
    "txt_files_in_results = [f for f in os.listdir(fpath2results) if \".txt\" in f]\n",
    "\n",
    "avg_files_Meso = [f\"{fpath2results}{f}\" for f in txt_files_in_results if \"v2avg.txt\" in f and \"Meso4\" in f]\n",
    "rnd_files_Meso = [f\"{fpath2results}{f}\" for f in txt_files_in_results if \"v2rnd.txt\" in f and \"Meso4\" in f]\n",
    "avg_files_Inception = [f\"{fpath2results}{f}\" for f in txt_files_in_results if \"v2avg.txt\" in f and \"Inception\" in f]\n",
    "rnd_files_Inception = [f\"{fpath2results}{f}\" for f in txt_files_in_results if \"v2rnd.txt\" in f and \"Inception\" in f]\n",
    "run_avg_files_Meso = [f\"{fpath2results}{f}\" for f in txt_files_in_results if \"runningavg.txt\" in f and \"Meso4\" in f]\n",
    "run_rnd_files_Meso = [f\"{fpath2results}{f}\" for f in txt_files_in_results if \"runningrnd.txt\" in f and \"Meso4\" in f]\n",
    "run_avg_files_Inception = [f\"{fpath2results}{f}\" for f in txt_files_in_results if \"runningavg.txt\" in f and \"Inception\" in f]\n",
    "run_rnd_files_Inception = [f\"{fpath2results}{f}\" for f in txt_files_in_results if \"runningrnd.txt\" in f and \"Inception\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Meso4\n",
    "avg_pairs = rnd_pairs = np.asarray([])\n",
    "count = 0\n",
    "for filea, fileb in zip(avg_files_Meso, rnd_files_Meso):\n",
    "    avg_y_true, avg_y_pred = get_ytrueNpreds_from_file(filea)\n",
    "    for a, b in zip(avg_y_true, avg_y_pred):\n",
    "        avg_pairs=np.append(avg_pairs,((a,b)))\n",
    "    rnd_y_true, rnd_y_pred = get_ytrueNpreds_from_file(fileb)\n",
    "    for a, b in zip(rnd_y_true, rnd_y_pred):\n",
    "        rnd_pairs=np.append(rnd_pairs,((a,b)))\n",
    "avg_pairs = np.reshape(avg_pairs,(-1,2))\n",
    "rnd_pairs = np.reshape(rnd_pairs,(-1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(rnd_pairs[:,0] == avg_pairs[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other_Model\n",
    "avg_pairs = rnd_pairs = np.asarray([])\n",
    "for filea, fileb in zip(avg_files_Inception, rnd_files_Inception):\n",
    "    avg_y_true, avg_y_pred = get_ytrueNpreds_from_file(filea)\n",
    "    for a, b in zip(avg_y_true, avg_y_pred):\n",
    "        avg_pairs=np.append(avg_pairs,((a,b)))\n",
    "    rnd_y_true, rnd_y_pred = get_ytrueNpreds_from_file(fileb)\n",
    "    for a, b in zip(rnd_y_true, rnd_y_pred):\n",
    "        rnd_pairs=np.append(rnd_pairs,((a,b)))\n",
    "avg_pairs = np.reshape(avg_pairs,(-1,2))\n",
    "rnd_pairs = np.reshape(rnd_pairs,(-1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnd_pairs[:,0][:10], rnd_pairs[:,1][:10], avg_pairs[:,1][:10]\n",
    "len_preds = 1000000000\n",
    "# for t, p1, p2 in zip(rnd_pairs[:,0][:len_preds], rnd_pairs[:,1][:len_preds], avg_pairs[:,1][:len_preds]):\n",
    "#     print(f\"{int(t)}, {int(p1>.5)}, {int(p2>.5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.45983521e-07]] [[1.45983521e-07]]\n"
     ]
    }
   ],
   "source": [
    "z_score_Inception, p_value_Inception = delong_roc_test(rnd_pairs[:,0][:len_preds], rnd_pairs[:,1][:len_preds], avg_pairs[:,1][:len_preds])\n",
    "z_score_Meso, p_value_Meso = delong_roc_test(rnd_pairs[:,0][:len_preds], rnd_pairs[:,1][:len_preds], avg_pairs[:,1][:len_preds])\n",
    "\n",
    "\n",
    "print(10**p_value_Inception, 10**p_value_Meso)\n",
    "# print(z_score_Inception, z_score_Meso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.45983521e-07]] [[1.45983521e-07]]\n"
     ]
    }
   ],
   "source": [
    "z_score_Inception, p_value_Inception = delong_roc_test(rnd_pairs[:,0], rnd_pairs[:,1], avg_pairs[:,1])\n",
    "z_score_Meso, p_value_Meso = delong_roc_test(rnd_pairs[:,0], rnd_pairs[:,1], avg_pairs[:,1])\n",
    "\n",
    "\n",
    "print(10**p_value_Inception, 10**p_value_Meso)\n",
    "# print(z_score_Inception, z_score_Meso)\n",
    "# Under the null hypothesis, z can be well approximated by the standard normal distribution. \n",
    "# Therefore, if the value of z deviates too much from zero, e.g., z > 1.96, it is thus reasonable \n",
    "# to consider that [theta(A) > theta(B)] with the significance level p < 0.05.\n",
    "\n",
    "# Here theta(A) is model rnd and theta(B) is model avg\n",
    "print(10**p_value_Inception, 10**p_value_Meso)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "103b48ebf1aa2242c051892b45e13b26f3e433ba168cde98ac0c97b247123e4d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
